{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "TinyStories_SLMs",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets -q"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:09:24.085186Z",
          "iopub.execute_input": "2025-07-02T17:09:24.085374Z",
          "iopub.status.idle": "2025-07-02T17:09:28.951408Z",
          "shell.execute_reply.started": "2025-07-02T17:09:24.085358Z",
          "shell.execute_reply": "2025-07-02T17:09:28.950699Z"
        },
        "id": "nu7kZnIdipkt",
        "outputId": "a4a20a6f-eca4-48c7-adcf-aee0b4fedd8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "HF_TOKEN = \"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\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:09:28.953323Z",
          "iopub.execute_input": "2025-07-02T17:09:28.953614Z",
          "iopub.status.idle": "2025-07-02T17:09:28.957801Z",
          "shell.execute_reply.started": "2025-07-02T17:09:28.953561Z",
          "shell.execute_reply": "2025-07-02T17:09:28.95699Z"
        },
        "id": "loTAOBeaipkw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"roneneldan/TinyStories\", token=HF_TOKEN)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:09:28.958565Z",
          "iopub.execute_input": "2025-07-02T17:09:28.958783Z",
          "iopub.status.idle": "2025-07-02T17:09:43.400999Z",
          "shell.execute_reply.started": "2025-07-02T17:09:28.958767Z",
          "shell.execute_reply": "2025-07-02T17:09:43.400174Z"
        },
        "colab": {
          "referenced_widgets": [
            "c455b597721640f1af6fb1097d613188",
            "af149be234524749acb8f8e544663a63",
            "3b0f8b4898bb4b3fb43bdb042ef0c36a",
            "2fdef61240e44c8f8485747ecd577c81",
            "4cc6162cbfc34032bcf54683bc3cf7f9",
            "ffb5e905fa464953ab8019bf836a6635",
            "3c05138373804c40af6b786b3955d30e",
            "b77e0382bf1b4fbfa46ae61df652c080"
          ]
        },
        "id": "5r3UjAbcipkw",
        "outputId": "ad4dd8e0-a539-4316-e812-be28496ae36f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c455b597721640f1af6fb1097d613188"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "(…)-00000-of-00004-2d5a1467fff1081b.parquet:   0%|          | 0.00/249M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af149be234524749acb8f8e544663a63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "(…)-00001-of-00004-5852b56a2bd28fd9.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b0f8b4898bb4b3fb43bdb042ef0c36a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "(…)-00002-of-00004-a26307300439e943.parquet:   0%|          | 0.00/246M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fdef61240e44c8f8485747ecd577c81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "(…)-00003-of-00004-d243063613e5a057.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cc6162cbfc34032bcf54683bc3cf7f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "(…)-00000-of-00001-869c898b519ad725.parquet:   0%|          | 0.00/9.99M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffb5e905fa464953ab8019bf836a6635"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/2119719 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c05138373804c40af6b786b3955d30e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split:   0%|          | 0/21990 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b77e0382bf1b4fbfa46ae61df652c080"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:09:43.401881Z",
          "iopub.execute_input": "2025-07-02T17:09:43.402387Z",
          "iopub.status.idle": "2025-07-02T17:09:43.406989Z",
          "shell.execute_reply.started": "2025-07-02T17:09:43.402358Z",
          "shell.execute_reply": "2025-07-02T17:09:43.406484Z"
        },
        "id": "fbS34wj4ipkw",
        "outputId": "2e6c3e0e-1360-4823-917a-e3d7155237f0"
      },
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 2119719\n    })\n    validation: Dataset({\n        features: ['text'],\n        num_rows: 21990\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train']['text'][100]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:09:43.407781Z",
          "iopub.execute_input": "2025-07-02T17:09:43.408076Z",
          "iopub.status.idle": "2025-07-02T17:09:52.249747Z",
          "shell.execute_reply.started": "2025-07-02T17:09:43.408059Z",
          "shell.execute_reply": "2025-07-02T17:09:52.248866Z"
        },
        "id": "Is099iFSipkw",
        "outputId": "e1a7259b-9b3d-47be-ca9a-125b5f9aa663"
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "\"There was a little girl with dark hair. Her name was Joy. She lived in a big house with her parents. One day, Joy was playing outside in her garden. Suddenly, she felt something on her leg - something pinching her. It was a big, black bug! \\n\\nJoy screamed and tried to get away, but the bug kept following her. She tried to run and hide, but it was too quick. \\n\\nJoy's parents heard her cries and came running. They used a stick to help her get rid of the bug. After the bug was gone, they hugged Joy and told her everything would be alright. \\n\\nWhen the bug was gone, Joy felt relieved and happy. She went back to playing in the garden, making sure she didn't step on any more bugs.\""
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenized the Dataset"
      ],
      "metadata": {
        "id": "nH9xuf0-ipkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken -q"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:09:52.251813Z",
          "iopub.execute_input": "2025-07-02T17:09:52.252049Z",
          "iopub.status.idle": "2025-07-02T17:09:58.595549Z",
          "shell.execute_reply.started": "2025-07-02T17:09:52.252032Z",
          "shell.execute_reply": "2025-07-02T17:09:58.594419Z"
        },
        "id": "ll5CmCX8ipky"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "enc = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:09:58.596531Z",
          "iopub.execute_input": "2025-07-02T17:09:58.596829Z",
          "iopub.status.idle": "2025-07-02T17:09:59.950088Z",
          "shell.execute_reply.started": "2025-07-02T17:09:58.596802Z",
          "shell.execute_reply": "2025-07-02T17:09:59.949241Z"
        },
        "id": "obpqEm6Dipky"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def process(example):\n",
        "    ids = enc.encode_ordinary(example['text'])\n",
        "    out = {'ids': ids, 'len':len(ids)}\n",
        "    return out\n",
        "\n",
        "if not os.path.exists(\"train.bin\"):\n",
        "    tokenized = ds.map(\n",
        "        process,\n",
        "        remove_columns=['text'],\n",
        "        desc=\"tokenizing the splits\",\n",
        "        num_proc=8,\n",
        "    )\n",
        "\n",
        "    for split, dset in tokenized.items():\n",
        "        arr_len = np.sum(dset['len'], dtype=np.uint64)\n",
        "        filename = f'{split}.bin'\n",
        "        dtype = np.uint16\n",
        "        arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,))\n",
        "        total_batches = 1024\n",
        "\n",
        "        idx = 0\n",
        "        for batch_idx in tqdm(range(total_batches), desc=f'writing {filename}'):\n",
        "            batch = dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True).with_format('numpy')\n",
        "            arr_batch = np.concatenate(batch['ids'])\n",
        "            arr[idx: idx+len(arr_batch)] = arr_batch\n",
        "            idx += len(arr_batch)\n",
        "        arr.flush()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:09:59.951011Z",
          "iopub.execute_input": "2025-07-02T17:09:59.95125Z",
          "iopub.status.idle": "2025-07-02T17:13:25.807636Z",
          "shell.execute_reply.started": "2025-07-02T17:09:59.95123Z",
          "shell.execute_reply": "2025-07-02T17:13:25.806788Z"
        },
        "colab": {
          "referenced_widgets": [
            "d2a81bfb31874d0fac70d3f28fa67a09",
            "1fa44b107ee543bd825f7df2a3d3ee04",
            "102ebd02a10c4f80895d398c92983291",
            "63ffd65409884526a127fc97badf03af"
          ]
        },
        "id": "uPKmsYWpipkz",
        "outputId": "87fd72d6-5c3e-47d2-cf6e-c792eade60f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizing the splits (num_proc=8):   0%|          | 0/2119719 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2a81bfb31874d0fac70d3f28fa67a09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizing the splits (num_proc=8):   0%|          | 0/21990 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fa44b107ee543bd825f7df2a3d3ee04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "writing train.bin:   0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "102ebd02a10c4f80895d398c92983291"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "writing validation.bin:   0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63ffd65409884526a127fc97badf03af"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "    if split == 'train':\n",
        "        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n",
        "    else:\n",
        "        data = np.memmap('validation.bin', dtype=np.uint16, mode='r')\n",
        "\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
        "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
        "    if device_type == 'cuda':\n",
        "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
        "    else:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:13:25.808716Z",
          "iopub.execute_input": "2025-07-02T17:13:25.808947Z",
          "iopub.status.idle": "2025-07-02T17:13:25.815249Z",
          "shell.execute_reply.started": "2025-07-02T17:13:25.808924Z",
          "shell.execute_reply": "2025-07-02T17:13:25.814506Z"
        },
        "id": "tkiodjyhipkz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "JqUak7z4ipkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from contextlib import nullcontext\n",
        "import os\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, ndim, bias):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(ndim))\n",
        "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.layer_norm(x, self.weight.shape, self.weight, self.bias, 1e-5)\n",
        "\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3*config.n_embd, bias=config.bias)\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.attn_dropout = nn.Dropout(config.dropout)\n",
        "        self.resid_dropout = nn.Dropout(config.dropout)\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.flash = hasattr(F, 'scaled_dot_product_attention')\n",
        "        if not self.flash:\n",
        "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "\n",
        "        if self.flash:\n",
        "            y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.attn_dropout.p if self.training else 0.0, is_causal=True)\n",
        "        else:\n",
        "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            att = self.attn_dropout(att)\n",
        "            y = att @ v\n",
        "\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc = nn.Linear(config.n_embd, 4*config.n_embd, bias=config.bias)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.dropout(self.c_proj(self.gelu(self.c_fc(x))))\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln1 = LayerNorm(config.n_embd, config.bias)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln2 = LayerNorm(config.n_embd, config.bias)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int\n",
        "    vocab_size: int\n",
        "    n_layer: int\n",
        "    n_head: int\n",
        "    n_embd: int\n",
        "    dropout: float = 0.0\n",
        "    bias: bool = True\n",
        "\n",
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte=nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe=nn.Embedding(config.block_size, config.n_embd),\n",
        "            drop=nn.Dropout(config.dropout),\n",
        "            h=nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f=LayerNorm(config.n_embd, config.bias),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                nn.init.normal_(p, mean=0.0, std=0.02 / math.sqrt(2 * config.n_layer))\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.config.block_size\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device)\n",
        "\n",
        "        tok_emb = self.transformer.wte(idx)\n",
        "        pos_emb = self.transformer.wpe(pos)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            logits = self.lm_head(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "            return logits, loss\n",
        "        else:\n",
        "            logits = self.lm_head(x[:, [-1], :])\n",
        "            return logits, None\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "            logits, _ = self(idx_cond)\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:13:25.81604Z",
          "iopub.execute_input": "2025-07-02T17:13:25.816378Z",
          "iopub.status.idle": "2025-07-02T17:13:29.994195Z",
          "shell.execute_reply.started": "2025-07-02T17:13:25.816353Z",
          "shell.execute_reply": "2025-07-02T17:13:29.993614Z"
        },
        "id": "UNXPTxCMipkz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "config = GPTConfig(\n",
        "    vocab_size=50257,\n",
        "    block_size=128,\n",
        "    n_layer=6,\n",
        "    n_head=6,\n",
        "    n_embd=384,\n",
        "    dropout=0.1,\n",
        "    bias=True\n",
        ")\n",
        "\n",
        "model = GPT(config)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:13:29.994933Z",
          "iopub.execute_input": "2025-07-02T17:13:29.995176Z",
          "iopub.status.idle": "2025-07-02T17:13:30.769524Z",
          "shell.execute_reply.started": "2025-07-02T17:13:29.995152Z",
          "shell.execute_reply": "2025-07-02T17:13:30.768734Z"
        },
        "id": "axLPzgsOipk0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:13:30.770382Z",
          "iopub.execute_input": "2025-07-02T17:13:30.771347Z",
          "iopub.status.idle": "2025-07-02T17:13:30.776537Z",
          "shell.execute_reply.started": "2025-07-02T17:13:30.771315Z",
          "shell.execute_reply": "2025-07-02T17:13:30.775828Z"
        },
        "id": "rwktWxyAipk0",
        "outputId": "0313cd8d-fff8-48fd-d350-a96f26b82654"
      },
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "GPT(\n  (transformer): ModuleDict(\n    (wte): Embedding(50257, 384)\n    (wpe): Embedding(128, 384)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-5): 6 x Block(\n        (ln1): LayerNorm()\n        (attn): CausalSelfAttention(\n          (c_attn): Linear(in_features=384, out_features=1152, bias=True)\n          (c_proj): Linear(in_features=384, out_features=384, bias=True)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln2): LayerNorm()\n        (mlp): MLP(\n          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n          (gelu): GELU(approximate='none')\n          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm()\n  )\n  (lm_head): Linear(in_features=384, out_features=50257, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_loss(model):\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for split in ['train', 'val']:\n",
        "            losses = torch.zeros(eval_iters)\n",
        "            for k in range(eval_iters):\n",
        "                X, Y = get_batch(split)\n",
        "                with ctx:\n",
        "                    logits, loss = model(X, Y)\n",
        "                losses[k] = loss.item()\n",
        "            out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:13:30.777382Z",
          "iopub.execute_input": "2025-07-02T17:13:30.777841Z",
          "iopub.status.idle": "2025-07-02T17:13:30.791351Z",
          "shell.execute_reply.started": "2025-07-02T17:13:30.777822Z",
          "shell.execute_reply": "2025-07-02T17:13:30.790753Z"
        },
        "id": "AMwo8Svmipk0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from contextlib import nullcontext\n",
        "\n",
        "learning_rate = 1e-4\n",
        "max_iters = 25000\n",
        "warmup_steps = 1000\n",
        "min_lr = 5e-4\n",
        "eval_iters = 500\n",
        "batch_size = 32\n",
        "block_size = 128\n",
        "\n",
        "gradient_accumulation_steps = 32\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device_type = 'cuda' if 'cuda' in device else 'cpu'\n",
        "\n",
        "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
        "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
        "\n",
        "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
        "\n",
        "torch.set_default_device(device)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:13:30.792217Z",
          "iopub.execute_input": "2025-07-02T17:13:30.792473Z",
          "iopub.status.idle": "2025-07-02T17:13:31.103339Z",
          "shell.execute_reply.started": "2025-07-02T17:13:30.792457Z",
          "shell.execute_reply": "2025-07-02T17:13:31.10255Z"
        },
        "id": "rQY1CL8Nipk0",
        "outputId": "e288edf0-23bc-48b9-c1be-5c5c7026100b"
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<torch._C.Generator at 0x7cd67f22de10>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import LinearLR, SequentialLR, CosineAnnealingLR\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1, eps=1e-9)\n",
        "\n",
        "scheduler_warmup = LinearLR(optimizer, total_iters = warmup_steps)\n",
        "scheduler_decay = CosineAnnealingLR(optimizer,T_max = max_iters - warmup_steps, eta_min = min_lr)\n",
        "scheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_decay], milestones=[warmup_steps])\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:13:31.104196Z",
          "iopub.execute_input": "2025-07-02T17:13:31.104464Z",
          "iopub.status.idle": "2025-07-02T17:13:34.003473Z",
          "shell.execute_reply.started": "2025-07-02T17:13:31.10444Z",
          "shell.execute_reply": "2025-07-02T17:13:34.002801Z"
        },
        "id": "g51K38uvipk0",
        "outputId": "7ca89f10-ea3c-48df-dc45-834e6b457e40"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_35/126589143.py:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "best_model_params_path = \"best_model_params.pt\"\n",
        "train_loss_list, validation_loss_list = [], []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in tqdm(range(max_iters)):\n",
        "    if epoch % eval_iters == 0 and epoch != 0:\n",
        "        losses = estimate_loss(model)\n",
        "        print(f\"Epoch {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "        print(f\"The current learning rate: {optimizer.param_groups[0]['lr']:.5f}\")\n",
        "        train_loss_list += [losses['train']]\n",
        "        validation_loss_list += [losses['val']]\n",
        "\n",
        "        if losses['val'] < best_val_loss:\n",
        "            best_val_loss = losses['val']\n",
        "            torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    X, y = get_batch(\"train\")\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    with ctx:\n",
        "        logits, loss = model(X, y)\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "    if ((epoch + 1) % gradient_accumulation_steps == 0) or (epoch + 1 == max_iters):\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "    scheduler.step()\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T17:13:34.0042Z",
          "iopub.execute_input": "2025-07-02T17:13:34.004645Z",
          "iopub.status.idle": "2025-07-02T21:53:11.596557Z",
          "shell.execute_reply.started": "2025-07-02T17:13:34.004626Z",
          "shell.execute_reply": "2025-07-02T21:53:11.595617Z"
        },
        "colab": {
          "referenced_widgets": [
            "31536e74b2c84b46951ed269a027a28f"
          ]
        },
        "id": "tiqWWMYPipk0",
        "outputId": "29d89f1e-ff3c-40c5-dbe8-6e10a5703dfc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/25000 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31536e74b2c84b46951ed269a027a28f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 500: train loss 9.4585, val loss 9.4644\nThe current learning rate: 0.00007\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1000: train loss 8.5262, val loss 8.5328\nThe current learning rate: 0.00010\nEpoch 1500: train loss 7.5645, val loss 7.5658\nThe current learning rate: 0.00010\nEpoch 2000: train loss 6.7192, val loss 6.7169\nThe current learning rate: 0.00010\nEpoch 2500: train loss 6.0299, val loss 6.0256\nThe current learning rate: 0.00010\nEpoch 3000: train loss 5.5222, val loss 5.5263\nThe current learning rate: 0.00011\nEpoch 3500: train loss 5.1080, val loss 5.1080\nThe current learning rate: 0.00011\nEpoch 4000: train loss 4.7927, val loss 4.7901\nThe current learning rate: 0.00012\nEpoch 4500: train loss 4.5483, val loss 4.5523\nThe current learning rate: 0.00012\nEpoch 5000: train loss 4.3357, val loss 4.3446\nThe current learning rate: 0.00013\nEpoch 5500: train loss 4.1850, val loss 4.1839\nThe current learning rate: 0.00013\nEpoch 6000: train loss 4.0218, val loss 4.0223\nThe current learning rate: 0.00014\nEpoch 6500: train loss 3.8808, val loss 3.8875\nThe current learning rate: 0.00015\nEpoch 7000: train loss 3.7759, val loss 3.7767\nThe current learning rate: 0.00016\nEpoch 7500: train loss 3.6700, val loss 3.6718\nThe current learning rate: 0.00017\nEpoch 8000: train loss 3.5743, val loss 3.5787\nThe current learning rate: 0.00018\nEpoch 8500: train loss 3.4904, val loss 3.4909\nThe current learning rate: 0.00019\nEpoch 9000: train loss 3.4015, val loss 3.4074\nThe current learning rate: 0.00020\nEpoch 9500: train loss 3.3379, val loss 3.3458\nThe current learning rate: 0.00021\nEpoch 10000: train loss 3.2550, val loss 3.2683\nThe current learning rate: 0.00022\nEpoch 10500: train loss 3.1961, val loss 3.1968\nThe current learning rate: 0.00024\nEpoch 11000: train loss 3.1402, val loss 3.1404\nThe current learning rate: 0.00025\nEpoch 11500: train loss 3.0709, val loss 3.0777\nThe current learning rate: 0.00026\nEpoch 12000: train loss 3.0184, val loss 3.0260\nThe current learning rate: 0.00027\nEpoch 12500: train loss 2.9679, val loss 2.9722\nThe current learning rate: 0.00029\nEpoch 13000: train loss 2.9243, val loss 2.9243\nThe current learning rate: 0.00030\nEpoch 13500: train loss 2.8760, val loss 2.8792\nThe current learning rate: 0.00031\nEpoch 14000: train loss 2.8359, val loss 2.8353\nThe current learning rate: 0.00033\nEpoch 14500: train loss 2.7817, val loss 2.7877\nThe current learning rate: 0.00034\nEpoch 15000: train loss 2.7521, val loss 2.7570\nThe current learning rate: 0.00035\nEpoch 15500: train loss 2.7127, val loss 2.7165\nThe current learning rate: 0.00036\nEpoch 16000: train loss 2.6775, val loss 2.6731\nThe current learning rate: 0.00038\nEpoch 16500: train loss 2.6454, val loss 2.6387\nThe current learning rate: 0.00039\nEpoch 17000: train loss 2.5978, val loss 2.6007\nThe current learning rate: 0.00040\nEpoch 17500: train loss 2.5654, val loss 2.5734\nThe current learning rate: 0.00041\nEpoch 18000: train loss 2.5377, val loss 2.5408\nThe current learning rate: 0.00042\nEpoch 18500: train loss 2.5161, val loss 2.5236\nThe current learning rate: 0.00043\nEpoch 19000: train loss 2.4856, val loss 2.4857\nThe current learning rate: 0.00044\nEpoch 19500: train loss 2.4615, val loss 2.4603\nThe current learning rate: 0.00045\nEpoch 20000: train loss 2.4332, val loss 2.4330\nThe current learning rate: 0.00046\nEpoch 20500: train loss 2.4076, val loss 2.4119\nThe current learning rate: 0.00047\nEpoch 21000: train loss 2.3879, val loss 2.3913\nThe current learning rate: 0.00047\nEpoch 21500: train loss 2.3686, val loss 2.3660\nThe current learning rate: 0.00048\nEpoch 22000: train loss 2.3398, val loss 2.3439\nThe current learning rate: 0.00048\nEpoch 22500: train loss 2.3191, val loss 2.3360\nThe current learning rate: 0.00049\nEpoch 23000: train loss 2.3063, val loss 2.3160\nThe current learning rate: 0.00049\nEpoch 23500: train loss 2.2887, val loss 2.2925\nThe current learning rate: 0.00050\nEpoch 24000: train loss 2.2818, val loss 2.2856\nThe current learning rate: 0.00050\nEpoch 24500: train loss 2.2552, val loss 2.2620\nThe current learning rate: 0.00050\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train_loss_list_converted = [i.cpu().detach() for i in train_loss_list]\n",
        "validation_loss_list_converted = [i.cpu().detach() for i in validation_loss_list]\n",
        "\n",
        "plt.plot(train_loss_list_converted, 'g', label='train_loss')\n",
        "plt.plot(validation_loss_list_converted, 'r', label='validation_loss')\n",
        "plt.xlabel(\"Steps - Every 100 epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T21:53:11.597419Z",
          "iopub.execute_input": "2025-07-02T21:53:11.597697Z",
          "iopub.status.idle": "2025-07-02T21:53:11.819819Z",
          "shell.execute_reply.started": "2025-07-02T21:53:11.597669Z",
          "shell.execute_reply": "2025-07-02T21:53:11.819079Z"
        },
        "id": "wm9FfQ7Pipk1",
        "outputId": "95609cb5-4a97-4cc9-b601-943634dba4c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT(config)\n",
        "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "best_model_params_path = \"best_model_params.pt\"\n",
        "model.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device)))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T21:53:11.82209Z",
          "iopub.execute_input": "2025-07-02T21:53:11.822302Z",
          "iopub.status.idle": "2025-07-02T21:53:11.933258Z",
          "shell.execute_reply.started": "2025-07-02T21:53:11.822286Z",
          "shell.execute_reply": "2025-07-02T21:53:11.932686Z"
        },
        "id": "OFTCVuQDipk1",
        "outputId": "1942f1a0-38ed-4fc0-ebf5-d6356062b014"
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Once upon a time there was a pumpkin.\"\n",
        "context = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\n",
        "y = model.generate(context, 200)\n",
        "print(enc.decode(y.squeeze().tolist()))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T21:53:11.933936Z",
          "iopub.execute_input": "2025-07-02T21:53:11.934197Z",
          "iopub.status.idle": "2025-07-02T21:53:13.107406Z",
          "shell.execute_reply.started": "2025-07-02T21:53:11.93418Z",
          "shell.execute_reply": "2025-07-02T21:53:13.106613Z"
        },
        "id": "aLyCt9QBipk1",
        "outputId": "09473369-3410-40ed-8b8e-5a1252a10a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Once upon a time there was a pumpkin. The tomato was very soft and bloom. Every day, it would shine the air in the sun. One day, the butter started to teach the rabbit how to make its plant sweet.\n\nThe spfy pot was so free! The girl was happy that of all the ingredients can make sure that it was energetic. She carefully wrapped the panty on blue.\n\nFinally, after being healed, it smelled nice. The sun rose too and felt happy. The peach was very beautiful. They were happy to meet the pear for a wedding of it.\n\nThe mom and the girl were no longer surprised. She hugged and said, â€œI do it for you. Daisy, if you offer up, we can work together.â€\n\nThe water rushed to the eats growing so she could carry them back. She gave them a question and thanked her mom. She said, â€œI learned a new way. Thatâ€™d expect\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters: {total_params}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-02T21:53:13.108362Z",
          "iopub.execute_input": "2025-07-02T21:53:13.108717Z",
          "iopub.status.idle": "2025-07-02T21:53:13.113095Z",
          "shell.execute_reply.started": "2025-07-02T21:53:13.108688Z",
          "shell.execute_reply": "2025-07-02T21:53:13.112477Z"
        },
        "id": "HzTGO3Shipk1",
        "outputId": "493ed25c-8419-4bcc-ef29-eff506181f4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total trainable parameters: 29995392\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "PQYKNGgPipk1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd15c643"
      },
      "source": [
        "# TinyStories GPT\n",
        "\n",
        "This project implements a character-level GPT model trained on the TinyStories dataset. The model is built using PyTorch and demonstrates the core concepts of a transformer-based language model.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "The model is trained on the [TinyStories dataset](https://huggingface.co/datasets/roneneldan/TinyStories), which consists of short stories suitable for training small language models.\n",
        "\n",
        "## Model Architecture\n",
        "\n",
        "The model is a decoder-only transformer with the following key components:\n",
        "\n",
        "- **Layer Normalization:** Applied before attention and feed-forward layers.\n",
        "- **Causal Self-Attention:** Implements masked self-attention to ensure that the model only attends to previous tokens.\n",
        "- **MLP:** A simple feed-forward network with a GELU activation.\n",
        "- **GPT:** The main model class that combines the embedding layers, transformer blocks, and the language modeling head.\n",
        "\n",
        "## Training\n",
        "\n",
        "The model is trained using the AdamW optimizer with a learning rate schedule that includes a warmup phase and cosine annealing. Mixed precision training is used when a compatible GPU is available.\n",
        "\n",
        "## Usage\n",
        "\n",
        "To use this model:\n",
        "\n",
        "1. **Install dependencies:**"
      ]
    }
  ]
}